# Rate Limit
MAX_REQUEST_PER_HOUR=

# Secret key
AUTH_SECRET_KEY=

# HTTPS PROXY
HTTPS_PROXY=

# 1: 调用模型接口的时使用前端传递的认证信息，在前端页面中的设置可以进行配置，如果前端没有传递则无法调用接口
# 2: 调用模型接口的时使用后端配置的认证信息，即使前端传递了也不使用。在进行 docker 部署的时候进行模型认证配置 
# 3: 调用模型接口的时优先使用前端传递的认证信息，如果前端没有传递，则使用后端配置的，如果都没有，则无法使用
# 调用模型接时使用认证信息的策略，默认值为 1
KEY_STRATEGY=1


# 获取模型的借口 优先级高于 MODEL_CONFIG
# MODEL_API=http://localhost:3002/getModels
# # 模型配置数据
# MODEL_CONFIG=[{"label":"gpt-3.5-turbo","value":"gpt-3.5-turbo","baseUrl":"http://ask.huat.xyz","apiKey":"sk-ashdjashjdk","chatAPI":"/vi"},{"label":"Kimi","value":"kimi","baseUrl":"http://kimi.ironc.cn","apiKey":"eyJhbGciOiJIUzUxMiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJ1c2VyLWNlbnRlciIsImV4cCI6MTcyMDUzNzg4NSwiaWF0IjoxNzEyNzYxODg1LCJqdGkiOiJjb2Jhbzc5a3FxNG44aWhkM2piMCIsInR5cCI6InJlZnJlc2giLCJzdWIiOiJjbnM1OTJvM3IwNzA2OGI0YmNoZyIsInNwYWNlX2lkIjoiY25zNTkybzNyMDcwNjhiNGJjaDAiLCJhYnN0cmFjdF91c2VyX2lkIjoiY25zNTkybzNyMDcwNjhiNGJjZ2cifQ.HQFe_L_amsLJXS8CMri0WSjtXY3D5aeQyAA1TZ8r3DFIu5Zpo80FAcZkMkwRBldNfSLizq5JWiEGaSJ1njHBOw","chatAPI":"/vi"}]

# 获取模型的借口 优先级高于 MODEL_CONFIG
MODEL_API=
# 模型配置数据
MODEL_CONFIG=


# 七牛云上传配置
Qiniuyun_ACCESS_KEY=
Qiniuyun_SECRET_KEY=
Qiniuyun_BUCKET_NAME=


# one api 配置
ONE_API_KEY=
ONE_API_BASE_URL=
ONE_API_Chat_API=

# openai 配置
OPENAI_API_KEY=
OPENAI_API_BASE_URL=
OPENAI_API_Chat_API=

# Kimi
Kimi_API_BASE_URL=
Kimi_API_KEY=
Kimi_Chat_API=

# 阶跃星辰
Step_API_BASE_URL=
Step_API_KEY= 
Step_Chat_API=

# 通义千问
Qwen_API_BASE_URL=
Qwen_API_KEY= 
Qwen_Chat_API=

# 智谱清言
Glm_API_BASE_URL=
Glm_API_KEY= 
Glm_Chat_API=

# 秘塔AI
Metaso_API_BASE_URL=
Metaso_API_KEY= 
Metaso_Chat_API=

# 聆心智能
Emohaa_API_BASE_URL=
Emohaa_API_KEY= 
Emohaa_Chat_API=